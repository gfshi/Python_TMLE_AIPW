{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is to estimate ATE based on doubly robust methods \n",
    "#  DR method 1: AIPW\n",
    "#  DR method 2: TMLE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "8  2.164947 -0.800811 -2.411401 -2.608424  1.602401 -2.471738 -1.638505   \n",
      "9 -0.243146 -1.562291 -0.268241 -1.207587  0.411936  0.462073 -0.464335   \n",
      "\n",
      "         X8  D         Y  \n",
      "0  0.912584  0  0.905900  \n",
      "1  0.131072  0  1.374393  \n",
      "2 -0.751875  0  1.618586  \n",
      "3  0.126175  0  1.236549  \n",
      "4  1.673362  0  0.303016  \n",
      "5 -1.072360  1  3.084399  \n",
      "6  0.312933  1  0.928333  \n",
      "7 -0.715902  1  3.251407  \n",
      "8  0.497176  1  1.645470  \n",
      "9 -0.231551  1  1.379011  \n",
      "\n",
      " True ATE: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "\n",
    "\n",
    "np.random.seed(123321)\n",
    "# Corr_matrix\n",
    "def generate_corr_matrix(k, seed = None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    A = np.random.randn(k, k)\n",
    "    A2 = A @ A.T   # Positive matrix \n",
    "    D = np.sqrt(np.diag(A2))\n",
    "    corr_mat = A2 / np.outer(D, D)\n",
    "    np.fill_diagonal(corr_mat, 1.0)\n",
    "    \n",
    "    return corr_mat\n",
    "\n",
    "# Generate data.frame with [Y, D, X]\n",
    "def generate_data(n, k):\n",
    "    theta = 0.5      # True ATE\n",
    "    b = 1 / np.arange(1, k + 1)  # Coefficients for X\n",
    "    mu = np.zeros(k)  # Mean vector for multivariate normal\n",
    "    cov = generate_corr_matrix(k)  # Correlation matrix\n",
    "    # Predictors: n by k\n",
    "    X = np.random.multivariate_normal(mu, cov, n)\n",
    "\n",
    "    score = X @ b\n",
    "    p_D = 1 / (1 + np.exp(-score))  # Propensity score (logistic)\n",
    "    D = np.random.binomial(1, p_D)  # Binary D\n",
    "\n",
    "    # Define structural outcome model\n",
    "    g = np.cos(score)**2\n",
    "    Y = theta  * D + g + np.random.normal(0, 1, n)\n",
    "\n",
    "    # DataFrame [Y, D, X]\n",
    "    columns = [f'X{i+1}' for i in range(k)]\n",
    "    df = pd.DataFrame(X, columns=columns)\n",
    "    df['D'] = D\n",
    "    df['Y'] = Y\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Geneate data with n=1000, k=8\n",
    "df = generate_data(1000, 8)\n",
    "df2 = df.copy()\n",
    "print(df2.head(10))\n",
    "theta = 0.5      # True ATE\n",
    "print('\\n True ATE:', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.078\n",
      "Model:                            OLS   Adj. R-squared:                  0.069\n",
      "Method:                 Least Squares   F-statistic:                     9.290\n",
      "Date:                Tue, 15 Apr 2025   Prob (F-statistic):           1.26e-13\n",
      "Time:                        02:43:36   Log-Likelihood:                -1494.4\n",
      "No. Observations:                1000   AIC:                             3009.\n",
      "Df Residuals:                     990   BIC:                             3058.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5044      0.050     10.105      0.000       0.406       0.602\n",
      "X1            -0.0208      0.045     -0.463      0.643      -0.109       0.067\n",
      "X2             0.0816      0.045      1.819      0.069      -0.006       0.170\n",
      "X3             0.0134      0.059      0.227      0.821      -0.103       0.130\n",
      "X4            -0.0380      0.096     -0.397      0.692      -0.226       0.150\n",
      "X5             0.0546      0.107      0.509      0.611      -0.156       0.265\n",
      "X6            -0.0138      0.058     -0.240      0.810      -0.127       0.099\n",
      "X7             0.1191      0.090      1.331      0.184      -0.057       0.295\n",
      "X8            -0.0303      0.108     -0.281      0.779      -0.242       0.182\n",
      "D              0.5513      0.078      7.094      0.000       0.399       0.704\n",
      "==============================================================================\n",
      "Omnibus:                        1.277   Durbin-Watson:                   2.026\n",
      "Prob(Omnibus):                  0.528   Jarque-Bera (JB):                1.294\n",
      "Skew:                          -0.033   Prob(JB):                        0.524\n",
      "Kurtosis:                       2.836   Cond. No.                         8.31\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "OLS Estimates: 0.5513091870973615\n",
      "Bias of OLS Estimates: 0.05130918709736154\n",
      "Percentage Bias of OLS Estimates: 10.261837419472307 %\n"
     ]
    }
   ],
   "source": [
    "#OLS estiamte \n",
    "XD_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'D']  # Covariates + D\n",
    "X_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']  # Covariates only\n",
    "Y_cols = ['Y']\n",
    "\n",
    "X = sm.add_constant(df[XD_cols], prepend=True)\n",
    "mod_ols = sm.OLS(df['Y'], X)\n",
    "res_ols = mod_ols.fit()\n",
    "print(res_ols.summary())\n",
    "\n",
    "#Statistics of OLS estimate \n",
    "theta_ols = res_ols.params['D']\n",
    "bias_ols = np.abs(theta_ols - theta)\n",
    "pct_bias_ols = ((theta_ols - theta) / theta) * 100\n",
    "print('\\nOLS Estimates:', theta_ols)\n",
    "print('Bias of OLS Estimates:', bias_ols)\n",
    "print('Percentage Bias of OLS Estimates:', pct_bias_ols, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMLE method \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "\n",
    "if df['Y'].between(0, 1).all():\n",
    "    outcome = 'binary'\n",
    "    df['Y_prob'] = df['Y']    # Binary Y\n",
    "else:\n",
    "    outcome = \"continuous\"\n",
    "    Y_min = df['Y'].min()\n",
    "    Y_max = df['Y'].max()\n",
    "    df['Y_prob'] = (df['Y'] - Y_min) / (Y_max - Y_min)\n",
    "    #df['Y_prob'] = df['Y_prob'].clip(0.001, 0.999)  #Avoid 0 or 1\n",
    "\n",
    "# Step 2: Define columns \n",
    "XD_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'D']  # Covariates + D\n",
    "X_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']  # Covariates only\n",
    "Y_cols = ['Y_prob']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "8  2.164947 -0.800811 -2.411401 -2.608424  1.602401 -2.471738 -1.638505   \n",
      "9 -0.243146 -1.562291 -0.268241 -1.207587  0.411936  0.462073 -0.464335   \n",
      "\n",
      "         X8  D         Y    Y_prob     Y_hat  D0  D1    Y1_hat    Y0_hat  \n",
      "0  0.912584  0  0.905900  0.529910  0.438268   0   1  0.520893  0.438268  \n",
      "1  0.131072  0  1.374393  0.600109  0.466673   0   1  0.549416  0.466673  \n",
      "2 -0.751875  0  1.618586  0.636699  0.472234   0   1  0.554936  0.472234  \n",
      "3  0.126175  0  1.236549  0.579454  0.458438   0   1  0.541202  0.458438  \n",
      "4  1.673362  0  0.303016  0.439573  0.440431   0   1  0.523084  0.440431  \n",
      "5 -1.072360  1  3.084399  0.856338  0.562432   0   1  0.562432  0.479817  \n",
      "6  0.312933  1  0.928333  0.533271  0.535985   0   1  0.535985  0.453231  \n",
      "7 -0.715902  1  3.251407  0.881362  0.580755   0   1  0.580755  0.498515  \n",
      "8  0.497176  1  1.645470  0.640727  0.532633   0   1  0.532633  0.449894  \n",
      "9 -0.231551  1  1.379011  0.600801  0.535609   0   1  0.535609  0.452856  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Outcome model \n",
    "X = sm.add_constant(df[XD_cols], prepend=True)\n",
    "mod_Y = sm.GLM(df['Y_prob'], X, \n",
    "              family=sm.families.Binomial(link=sm.families.links.Logit())).fit()\n",
    "\n",
    "#Predict Y_hat Y1_hat, Y0_hat\n",
    "df['Y_hat'] = mod_Y.predict(X.values)\n",
    "\n",
    "df['D0'] = 0 \n",
    "df['D1'] = 1  \n",
    "X1 = sm.add_constant(df[X_cols + ['D1']], has_constant='add', prepend=True)\n",
    "df['Y1_hat'] = mod_Y.predict(X1.values)   # X1 does not work as D1 is not D\n",
    "\n",
    "X0 = sm.add_constant(df[X_cols + ['D0']], has_constant='add', prepend=True)\n",
    "df['Y0_hat'] = mod_Y.predict(X0.values)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "8  2.164947 -0.800811 -2.411401 -2.608424  1.602401 -2.471738 -1.638505   \n",
      "9 -0.243146 -1.562291 -0.268241 -1.207587  0.411936  0.462073 -0.464335   \n",
      "\n",
      "         X8  D         Y    Y_prob     Y_hat  D0  D1    Y1_hat    Y0_hat  \\\n",
      "0  0.912584  0  0.905900  0.529910  0.438268   0   1  0.520893  0.438268   \n",
      "1  0.131072  0  1.374393  0.600109  0.466673   0   1  0.549416  0.466673   \n",
      "2 -0.751875  0  1.618586  0.636699  0.472234   0   1  0.554936  0.472234   \n",
      "3  0.126175  0  1.236549  0.579454  0.458438   0   1  0.541202  0.458438   \n",
      "4  1.673362  0  0.303016  0.439573  0.440431   0   1  0.523084  0.440431   \n",
      "5 -1.072360  1  3.084399  0.856338  0.562432   0   1  0.562432  0.479817   \n",
      "6  0.312933  1  0.928333  0.533271  0.535985   0   1  0.535985  0.453231   \n",
      "7 -0.715902  1  3.251407  0.881362  0.580755   0   1  0.580755  0.498515   \n",
      "8  0.497176  1  1.645470  0.640727  0.532633   0   1  0.532633  0.449894   \n",
      "9 -0.231551  1  1.379011  0.600801  0.535609   0   1  0.535609  0.452856   \n",
      "\n",
      "     ps_hat       Haw       H1w        H0w  \n",
      "0  0.303659 -1.436079  3.293162  -1.436079  \n",
      "1  0.303956 -1.436691  3.289951  -1.436691  \n",
      "2  0.267654 -1.365475  3.736168  -1.365475  \n",
      "3  0.399044 -1.664014  2.505992  -1.664014  \n",
      "4  0.327483 -1.486951  3.053596  -1.486951  \n",
      "5  0.534824  1.869775  1.869775  -2.149722  \n",
      "6  0.902765  1.107707  1.107707 -10.284409  \n",
      "7  0.635757  1.572928  1.572928  -2.745421  \n",
      "8  0.419770  2.382255  2.382255  -1.723455  \n",
      "9  0.147528  6.778371  6.778371  -1.173059  \n"
     ]
    }
   ],
   "source": [
    "# Step 4, PS model \n",
    "X = sm.add_constant(df[X_cols], prepend=True)\n",
    "mod_PS = sm.GLM(df['D'], X, family=sm.families.Binomial()).fit()\n",
    "\n",
    "ps_hat = mod_PS.predict(X)\n",
    "df['ps_hat'] = ps_hat\n",
    "\n",
    "# Define clever covariates\n",
    "df['Haw'] = df['D']/df['ps_hat'] - (1-df['D'])/(1-df['ps_hat'])\n",
    "df['H1w'] = (1/df['ps_hat'])\n",
    "df['H0w'] = -1/(1-df['ps_hat'])\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of epsilon is: -0.003870\n",
      "Epsilon0 (H0w): -0.0008, Epsilon1 (H1w): -0.0052\n"
     ]
    }
   ],
   "source": [
    "# Step 5, Derive Epsilon parameters  \n",
    "mod_eps = sm.GLM(df['Y_prob'], df[['Haw']], \n",
    "                 family=sm.families.Binomial(),  \n",
    "                 offset=logit(df['Y_hat'])).fit() \n",
    "epsilon = mod_eps.params['Haw']\n",
    "print(f'Values of epsilon is: {epsilon: 4f}')\n",
    "\n",
    "# Using two parameters\n",
    "X_eps = df[['H0w', 'H1w']] \n",
    "mod_eps = sm.GLM(df['Y_prob'], X_eps, \n",
    "                 family=sm.families.Binomial(),\n",
    "                 offset=logit(df['Y_hat'])).fit()\n",
    "# Extract epsilon parameters\n",
    "eps0 = mod_eps.params['H0w']\n",
    "eps1 = mod_eps.params['H1w']\n",
    "print(f'Epsilon0 (H0w): {eps0:.4f}, Epsilon1 (H1w): {eps1:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "8  2.164947 -0.800811 -2.411401 -2.608424  1.602401 -2.471738 -1.638505   \n",
      "9 -0.243146 -1.562291 -0.268241 -1.207587  0.411936  0.462073 -0.464335   \n",
      "\n",
      "         X8  D         Y  ...    Y1_hat    Y0_hat    ps_hat       Haw  \\\n",
      "0  0.912584  0  0.905900  ...  0.520893  0.438268  0.303659 -1.436079   \n",
      "1  0.131072  0  1.374393  ...  0.549416  0.466673  0.303956 -1.436691   \n",
      "2 -0.751875  0  1.618586  ...  0.554936  0.472234  0.267654 -1.365475   \n",
      "3  0.126175  0  1.236549  ...  0.541202  0.458438  0.399044 -1.664014   \n",
      "4  1.673362  0  0.303016  ...  0.523084  0.440431  0.327483 -1.486951   \n",
      "5 -1.072360  1  3.084399  ...  0.562432  0.479817  0.534824  1.869775   \n",
      "6  0.312933  1  0.928333  ...  0.535985  0.453231  0.902765  1.107707   \n",
      "7 -0.715902  1  3.251407  ...  0.580755  0.498515  0.635757  1.572928   \n",
      "8  0.497176  1  1.645470  ...  0.532633  0.449894  0.419770  2.382255   \n",
      "9 -0.231551  1  1.379011  ...  0.535609  0.452856  0.147528  6.778371   \n",
      "\n",
      "        H1w        H0w  Y1_update  Y0_update  Y1_update_scaled  \\\n",
      "0  3.293162  -1.436079   0.516635   0.438541          0.817309   \n",
      "1  3.289951  -1.436691   0.545195   0.466950          1.007908   \n",
      "2  3.736168  -1.365475   0.550152   0.472496          1.040996   \n",
      "3  2.505992  -1.664014   0.537978   0.458757          0.959748   \n",
      "4  3.053596  -1.486951   0.519138   0.440714          0.834010   \n",
      "5  1.869775  -2.149722   0.560048   0.480232          1.107037   \n",
      "6  1.107707 -10.284409   0.534558   0.455199          0.936921   \n",
      "7  1.572928  -2.745421   0.578771   0.499045          1.231987   \n",
      "8  2.382255  -1.723455   0.529560   0.450224          0.903570   \n",
      "9  6.778371  -1.173059   0.526868   0.453081          0.885600   \n",
      "\n",
      "   Y0_update_scaled  \n",
      "0          0.296127  \n",
      "1          0.485720  \n",
      "2          0.522739  \n",
      "3          0.431048  \n",
      "4          0.310630  \n",
      "5          0.574362  \n",
      "6          0.407302  \n",
      "7          0.699917  \n",
      "8          0.374096  \n",
      "9          0.393162  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: update Y1_hat and Y0_hat\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "    \n",
    "df['Y1_update'] = sigmoid(logit(df['Y1_hat']) + eps1 * df['H1w'])\n",
    "df['Y0_update'] = sigmoid(logit(df['Y0_hat']) + eps0 * df['H0w'])\n",
    "\n",
    "# Scale continuous predictions\n",
    "if outcome == \"continuous\":\n",
    "    df['Y1_update_scaled'] = (Y_max - Y_min) * df['Y1_update'] + Y_min\n",
    "    df['Y0_update_scaled'] = (Y_max - Y_min) * df['Y0_update'] + Y_min\n",
    "elif outcome == \"binary\":\n",
    "    df['Y1_update_scaled'] = df['Y1_update']\n",
    "    df['Y0_update_scaled'] = df['Y0_update']\n",
    "else:\n",
    "    raise ValueError(\"Outcome must be either 'binary' or 'continuous'.\")\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TMLE Estimates: 0.5196510734715327\n",
      "Bias of TMLE Estimates: 0.01965107347153272\n",
      "Percentage Bias of TMLE Estimates: 3.930214694306544 %\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Compute TMLE estimate\n",
    "theta_est = df['Y1_update_scaled'] - df['Y0_update_scaled']\n",
    "theta_tmle = theta_est.mean()\n",
    "bias_tmle = np.abs(theta_tmle  -theta)\n",
    "pct_bias_tmle = ((theta_tmle  - theta) / theta) * 100\n",
    "\n",
    "print('\\nTMLE Estimates:', theta_tmle )\n",
    "print('Bias of TMLE Estimates:', bias_tmle)\n",
    "print('Percentage Bias of TMLE Estimates:', pct_bias_tmle, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "\n",
      "         X8  D         Y  D1  D0    Y1_hat    Y0_hat  \n",
      "0  0.912584  0  0.905900   1   0  0.845841  0.294532  \n",
      "1  0.131072  0  1.374393   1   0  1.035547  0.484237  \n",
      "2 -0.751875  0  1.618586   1   0  1.072489  0.521180  \n",
      "3  0.126175  0  1.236549   1   0  0.980753  0.429444  \n",
      "4  1.673362  0  0.303016   1   0  0.860435  0.309126  \n",
      "5 -1.072360  1  3.084399   1   0  1.122742  0.571432  \n",
      "6  0.312933  1  0.928333   1   0  0.946142  0.394833  \n",
      "7 -0.715902  1  3.251407   1   0  1.246455  0.695146  \n"
     ]
    }
   ],
   "source": [
    "#AIPW method \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "XD_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'D']  # Covariates + D\n",
    "X_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']  \n",
    "    \n",
    "# Step 1: Outcome model (G-computation)\n",
    "X_outcome = sm.add_constant(df2[XD_cols], prepend=True)\n",
    "mod_Y = sm.GLM(df2['Y'], X_outcome, family=sm.families.Gaussian()).fit()\n",
    "\n",
    "df2['D1'] = 1\n",
    "df2['D0'] = 0\n",
    "X1 = sm.add_constant(df2[X_cols + ['D1']], has_constant='add', prepend=True)\n",
    "df2['Y1_hat'] = mod_Y.predict(X1)\n",
    "\n",
    "#X0 = sm.add_constant(df[X_cols + ['D0']], prepend=True)\n",
    "X0 = sm.add_constant(df2[X_cols + ['D0']], has_constant='add', prepend=True)\n",
    "df2['Y0_hat'] = mod_Y.predict(X0)\n",
    "\n",
    "print(df2.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.171745 -1.061727  0.266644 -0.093521 -1.695077  1.223727  0.086541   \n",
      "1 -0.582003 -0.460072  0.641401  0.256456 -0.649026  0.038970  0.389041   \n",
      "2 -0.390587 -0.948942 -0.457175  0.601283 -0.012413 -0.248519  0.751453   \n",
      "3  0.258854 -0.197598  0.559316 -1.185145  0.582350 -0.028826 -1.128971   \n",
      "4 -0.601644  0.739605  0.835163  0.435640 -1.943612 -1.120272 -1.019158   \n",
      "5  0.626916 -0.610890 -0.392059  0.310769  0.148834  0.821127  0.987841   \n",
      "6  1.225196  0.223089  1.888222  1.934322 -1.271216  1.291793  0.358159   \n",
      "7  0.257843  0.609101 -0.688733  0.256400  0.631261 -0.179882  0.896016   \n",
      "\n",
      "         X8  D         Y  D1  D0    Y1_hat    Y0_hat    ps_hat  \n",
      "0  0.912584  0  0.905900   1   0  0.845841  0.294532  0.303659  \n",
      "1  0.131072  0  1.374393   1   0  1.035547  0.484237  0.303956  \n",
      "2 -0.751875  0  1.618586   1   0  1.072489  0.521180  0.267654  \n",
      "3  0.126175  0  1.236549   1   0  0.980753  0.429444  0.399044  \n",
      "4  1.673362  0  0.303016   1   0  0.860435  0.309126  0.327483  \n",
      "5 -1.072360  1  3.084399   1   0  1.122742  0.571432  0.534824  \n",
      "6  0.312933  1  0.928333   1   0  0.946142  0.394833  0.902765  \n",
      "7 -0.715902  1  3.251407   1   0  1.246455  0.695146  0.635757  \n"
     ]
    }
   ],
   "source": [
    "#Step 2: PS model \n",
    "X_ps = sm.add_constant(df2[X_cols], prepend=True)\n",
    "mod_PS = sm.GLM(df2['D'], X_ps, family=sm.families.Binomial()).fit()\n",
    "df2['ps_hat'] = mod_PS.predict(X_ps)\n",
    "\n",
    "print(df2.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: AIPW estimate\n",
    "#G-computation \n",
    "df2['G_comp'] = df2['Y1_hat'] - df2['Y0_hat']\n",
    "# Adj\n",
    "df2['adj'] = (df2['D'] * (df2['Y'] - df2['Y1_hat']) / df2['ps_hat']) - (\n",
    "              (1 - df2['D']) * (df2['Y'] - df2['Y0_hat']) / (1 - df2['ps_hat']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AIPW Estimate: 0.5104665019240455\n",
      "Bias of AIPW Estimate: 0.010466501924045524\n",
      "Percentage Bias of AIPW Estimate: 2.0933003848091047 %\n"
     ]
    }
   ],
   "source": [
    "# AIPW statistics \n",
    "theta_est2 = df2['G_comp'] + df2['adj']\n",
    "theta_aipw = theta_est2.mean()\n",
    "bias_aipw = np.abs(theta_aipw  - theta)\n",
    "pct_bias_aipw = ((theta_aipw - theta) / theta) * 100\n",
    "\n",
    "\n",
    "print('\\nAIPW Estimate:', theta_aipw )\n",
    "print('Bias of AIPW Estimate:', bias_aipw)\n",
    "print('Percentage Bias of AIPW Estimate:', pct_bias_aipw, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Percentage Bias</th>\n",
       "      <th>True Effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.551309</td>\n",
       "      <td>0.051309</td>\n",
       "      <td>10.261837</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TMLE</td>\n",
       "      <td>0.519651</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>3.930215</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIPW</td>\n",
       "      <td>0.510467</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>2.093300</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  Estimate      Bias  Percentage Bias  True Effect\n",
       "0    OLS  0.551309  0.051309        10.261837          0.5\n",
       "1   TMLE  0.519651  0.019651         3.930215          0.5\n",
       "2   AIPW  0.510467  0.010467         2.093300          0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison \n",
    "results_comparison = pd.DataFrame({\n",
    "    'Method': ['OLS', 'TMLE', 'AIPW'],\n",
    "    'Estimate': [theta_ols, theta_tmle, theta_aipw],\n",
    "    'Bias': [bias_ols, bias_tmle, bias_aipw],\n",
    "    'Percentage Bias': [pct_bias_ols, pct_bias_tmle, pct_bias_aipw],\n",
    "    'True Effect': [theta, theta, theta]  # For reference\n",
    "})\n",
    "results_comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMLE reference\n",
    "Laan, Mark J van der, and Daniel Rubin. 2006. “Targeted Maximum Likelihood Learning.” The International Journal of Biostatistics 2 (1): 11.\n",
    "\n",
    "Schuler, Megan S, and Sherri Rose. 2017. “Targeted Maximum Likelihood Estimation for Causal Inference in Observational Studies.” American Journal of Epidemiology 185 (1): 65–73. \n",
    "\n",
    "### AIPW reference \n",
    "Bang, Heejung, and James M Robins. 2005. “Doubly Robust Estimation in Missing Data and Causal Inference Models.” Biometrics 61 (4): 962–73. \n",
    "\n",
    "Glynn, Adam N, and Kevin M Quinn. 2010. “An Introduction to the Augmented Inverse Propensity Weighted Estimator.” Political Analysis 18 (1): 36–56. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
